{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intellectual-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from flask import Flask, request, render_template\n",
    "import pickle\n",
    "import re\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n",
    "from data_utils import DocumentSentimentDataset, DocumentSentimentDataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suffering-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "slang = pd.read_csv('Datasets/Combined_Slang_Dictionary.csv')\n",
    "stopwords_id = pd.read_csv('Datasets/stopwords-id.txt',delimiter='\\n')\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "w2i, i2w = DocumentSentimentDataset.LABEL2INDEX, DocumentSentimentDataset.INDEX2LABEL\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spiritual-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open('Pickles/TFIDF/TFIDF_vectorizer.sav', 'rb'))\n",
    "tfidf_lr = pickle.load(open('Pickles/TFIDF/TFIDF_LR.sav', 'rb'))\n",
    "tfidf_svc = pickle.load(open('Pickles/TFIDF/TFIDF_SVC.sav', 'rb'))\n",
    "\n",
    "cbow_model = pickle.load(open('Pickles/Word2Vec/CBOW/cbow_model.sav', 'rb'))\n",
    "cbow_lr = pickle.load(open('Pickles/Word2Vec/CBOW/cbow_LR.sav', 'rb'))\n",
    "cbow_lr_ft = pickle.load(open('Pickles/Word2Vec/CBOW/cbow_LR_FT.sav', 'rb'))\n",
    "cbow_svc = pickle.load(open('Pickles/Word2Vec/CBOW/cbow_SVC.sav', 'rb'))\n",
    "\n",
    "skip_model = pickle.load(open('Pickles/Word2Vec/Skip/skip_model.sav', 'rb'))\n",
    "skip_lr = pickle.load(open('Pickles/Word2Vec/Skip/skip_LR.sav', 'rb'))\n",
    "skip_svc = pickle.load(open('Pickles/Word2Vec/Skip/skip_SVC.sav', 'rb'))\n",
    "\n",
    "indobert_before = torch.load('Pickles/indoBERT/before.pth', map_location=torch.device('cpu'))\n",
    "indobert_after = torch.load('Pickles/indoBERT/after.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "editorial-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(review):\n",
    "    temp = \"\"\n",
    "    tokenized = word_tokenize(review.lower())\n",
    "    \n",
    "    for j, word in enumerate(tokenized):\n",
    "        if word in stopwords_id['Stopwords'].values:\n",
    "            continue\n",
    "        else:\n",
    "            temp = temp + word + \" \"\n",
    "    \n",
    "    if temp == \"\":\n",
    "        temp = review\n",
    "    \n",
    "    temp = stemmer.stem(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "administrative-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(review):\n",
    "    review = re.sub(r'\\d+',' ', review)\n",
    "    review = re.sub(r'[^\\w\\s]',' ', review)\n",
    "    review = re.sub(r'\\s{2,}',' ', review)\n",
    "    \n",
    "    return data_preprocessing(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aboriginal-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slang_cleaning(review):\n",
    "    temp = \"\"\n",
    "    tokenized = word_tokenize(review.lower())                               \n",
    "    \n",
    "    for j, word in enumerate(tokenized):\n",
    "        flag = word in slang['Before'].values                         \n",
    "        \n",
    "        if flag == True:\n",
    "            slang_index = slang[slang['Before'] == word].index.values   \n",
    "            word = slang.at[slang_index[0], 'After']\n",
    "        \n",
    "        temp = temp + word + \" \"          \n",
    "        \n",
    "    return data_cleaning(temp)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "friendly-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorize(review):\n",
    "    temp = []\n",
    "    temp.append(review)\n",
    "    \n",
    "    tfidf = vectorizer.transform(temp)\n",
    "    \n",
    "    return tfidf_lr.predict(tfidf), tfidf_svc.predict(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oriented-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(review):\n",
    "    words = []\n",
    "\n",
    "    tokenized = word_tokenize(review)\n",
    "\n",
    "    for w in tokenized:\n",
    "        words.append(w)                   \n",
    "    \n",
    "    cbow_vec = []\n",
    "    skip_vec = []\n",
    "    \n",
    "    try:\n",
    "        res_cbow = np.mean(cbow_model[words], axis=0)\n",
    "        cbow_vec.append(res_cbow)\n",
    "        \n",
    "        res_skip = np.mean(skip_model[words], axis=0)\n",
    "        skip_vec.append(res_skip)\n",
    "    except KeyError:\n",
    "        cbow_model.build_vocab([words], update=True)\n",
    "        cbow_model.train(words, total_examples = -1, epochs=1)\n",
    "        \n",
    "        res_cbow = np.mean(cbow_model[words], axis=0)\n",
    "        cbow_vec.append(res_cbow)\n",
    "        \n",
    "        skip_model.build_vocab([words], update=True)\n",
    "        skip_model.train(words, total_examples = -1, epochs=1)\n",
    "        \n",
    "        res_skip = np.mean(skip_model[words], axis=0)\n",
    "        skip_vec.append(res_skip)\n",
    "    \n",
    "    cbow_vec = np.array(cbow_vec)\n",
    "    skip_vec = np.array(skip_vec)\n",
    "    \n",
    "    return cbow_lr.predict(cbow_vec), cbow_lr_ft.predict(cbow_vec), cbow_svc.predict(cbow_vec), skip_lr.predict(skip_vec), skip_svc.predict(skip_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "governing-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indo_sentiment(sentence):\n",
    "    subwords = tokenizer.encode(sentence)\n",
    "    \n",
    "    subwords_before = torch.LongTensor(subwords).view(1, -1).to(indobert_before.device)\n",
    "    subwords_after = torch.LongTensor(subwords).view(1, -1).to(indobert_after.device)\n",
    "    \n",
    "    logits_b = indobert_before(subwords_before)[0]\n",
    "    label_b = torch.topk(logits_b, k=1, dim=-1)[1].squeeze().item()\n",
    "    \n",
    "    logits_a = indobert_after(subwords_after)[0]\n",
    "    label_a = torch.topk(logits_a, k=1, dim=-1)[1].squeeze().item()\n",
    "    \n",
    "    return logits_b, label_b, logits_a, label_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "instrumental-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indo_bert(review):\n",
    "    logits_bef, label_bef, logits_aft, label_aft = indo_sentiment(review)\n",
    "    \n",
    "    return i2w[label_bef], i2w[label_aft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extensive-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = slang_cleaning(\"mantap jiwa produk ini, sangat recommended\")\n",
    "\n",
    "# res1, res2 = indo_bert(result)\n",
    "\n",
    "# print(res1)\n",
    "# print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "administrative-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [24/Jun/2022 21:18:56] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Jun/2022 21:19:07] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    review = str(request.form[\"reviews\"])\n",
    "    \n",
    "    cleaned_review = slang_cleaning(review)\n",
    "    \n",
    "    tfidf_lr, tfidf_svc = tfidf_vectorize(cleaned_review)\n",
    "    cbow_lr, cbow_lr_ft, cbow_svc, skip_lr, skip_svc = word2vec(cleaned_review)\n",
    "    indo_before, indo_after = indo_bert(cleaned_review)\n",
    "    \n",
    "    return render_template('index.html', \n",
    "                           original_review = f'{review}', \n",
    "                           preprocess = f'{cleaned_review}',\n",
    "                           res1=f'{tfidf_lr[0]}', \n",
    "                           res2=f'{tfidf_svc[0]}', \n",
    "                           res3=f'{cbow_lr[0]}', \n",
    "                           res4=f'{cbow_lr_ft[0]}', \n",
    "                           res5=f'{cbow_svc[0]}',\n",
    "                           res6=f'{skip_lr[0]}',\n",
    "                           res7=f'{skip_svc[0]}',\n",
    "                           res8=f'{indo_before.capitalize()}', \n",
    "                           res9=f'{indo_after.capitalize()}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-reserve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
